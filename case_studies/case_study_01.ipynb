{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 01: Clustering of Doctors' Notes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first case study in the ALADA couse is the problem of clustering medical notes using measures of similarities between vectors. We make use of a kaggle dataset for this purpose. The first step to running this notebook is to download the dataset and copy it into the data directory `data/case_study_01/`.\n",
    "\n",
    "Run the following two cells to import all the necessary libraries and to create the folder for the data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "# import pandas as pd\n",
    "import re\n",
    "import polars as pl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "import sys\n",
    "from alada import chap01 as ch01\n",
    "from alada import casestudy01 as cs01\n",
    "\n",
    "# Create data folder for the case study\n",
    "cs01.create_data_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Getting the data\n",
    "\n",
    "Link to the kaggle dataset: [https://www.kaggle.com/datasets/gauravmodi/doctors-notes/data](https://www.kaggle.com/datasets/gauravmodi/doctors-notes/data)\n",
    "\n",
    "Download the `reports.csv` file, and copy it into the folder `data/case_study_01/`. After you have done this, run the following cell and check if it reports success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success! You can run this notebook.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs01.check_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What does this dataset have?\n",
    "\n",
    "The data file is a `.csv` file. If you do not know that means, then take a look [here](https://en.wikipedia.org/wiki/Comma-separated_values).\n",
    "\n",
    "The file has two columns: `medical_specialty` and `report`.\n",
    "- The `medical_specialty` column contains the specialty of the doctor who wrote the report, and\n",
    "- the `report` column contains the actual text of the report written down by the doctor for a particular patient.\n",
    "\n",
    "For the purpose of this case study, we will only be using the `report` column; we will use the `medical_specialty` column only for evaluating the clustering results for us know how well out clustering algorithm has done.\n",
    "\n",
    "We have learned about clustering using n-vectors; objects containing numbers. How does one cluster text data? \n",
    "\n",
    "We do this by first converting the text data into n-vectors that represent, at least partially, the information contaning in the text. There are many ways to do this, but will make use a simple technique called `count vectorization`.\n",
    "\n",
    "**Count Vectorization** is a technique that converts text data into n-vectors by counting the number of times a set of `tokens` (chosen words) appears in the text. Tokens are words that are chosen from the text or given by a specialist from the field of study. Consider the following example:\n",
    "\n",
    "**Text to convert:** \"The quick brown fox jumps over the lazy dog. The dog is very lazy, but the fox is quick. The dog is friendly through.\"\n",
    "\n",
    "**Tokens:** [\"quick\", \"brown\", \"fox\", \"jumps\", \"lazy\", \"dog\"]\n",
    "\n",
    "We simply count the number of times each token appears in the text. The vector representation of the text is then: [2, 1, 2, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's read the reports.csv file and see what it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>medical_specialty</th><th>report</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Cardiovascular / Pulmonary&quot;</td><td>&quot;2-D M-MODE: , ,1.  Left atrial…</td></tr><tr><td>&quot;Cardiovascular / Pulmonary&quot;</td><td>&quot;1.  The left ventricular cavit…</td></tr><tr><td>&quot;Cardiovascular / Pulmonary&quot;</td><td>&quot;2-D ECHOCARDIOGRAM,Multiple vi…</td></tr><tr><td>&quot;Cardiovascular / Pulmonary&quot;</td><td>&quot;DESCRIPTION:,1.  Normal cardia…</td></tr><tr><td>&quot;Cardiovascular / Pulmonary&quot;</td><td>&quot;2-D STUDY,1. Mild aortic steno…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌────────────────────────────┬─────────────────────────────────┐\n",
       "│ medical_specialty          ┆ report                          │\n",
       "│ ---                        ┆ ---                             │\n",
       "│ str                        ┆ str                             │\n",
       "╞════════════════════════════╪═════════════════════════════════╡\n",
       "│ Cardiovascular / Pulmonary ┆ 2-D M-MODE: , ,1.  Left atrial… │\n",
       "│ Cardiovascular / Pulmonary ┆ 1.  The left ventricular cavit… │\n",
       "│ Cardiovascular / Pulmonary ┆ 2-D ECHOCARDIOGRAM,Multiple vi… │\n",
       "│ Cardiovascular / Pulmonary ┆ DESCRIPTION:,1.  Normal cardia… │\n",
       "│ Cardiovascular / Pulmonary ┆ 2-D STUDY,1. Mild aortic steno… │\n",
       "└────────────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data folder and file\n",
    "datadir = \"data/case_study_01\"\n",
    "datafile = (datadir / pathlib.Path(\"reports.csv\")).as_posix()\n",
    "tokensfile = (datadir / pathlib.Path(\"tokens.txt\")).as_posix()\n",
    "\n",
    "# Read the medical records file.\n",
    "medrec = pl.read_csv(datafile)\n",
    "\n",
    "# Let view the first five rows using the .head() function on the polar dataframe.\n",
    "medrec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>medical_specialty</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Gastroenterology&quot;</td><td>224</td></tr><tr><td>&quot;Cardiovascular / Pulmonary&quot;</td><td>371</td></tr><tr><td>&quot;Surgery&quot;</td><td>1088</td></tr><tr><td>&quot;Neurology&quot;</td><td>223</td></tr><tr><td>&quot;Radiology&quot;</td><td>273</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌────────────────────────────┬───────┐\n",
       "│ medical_specialty          ┆ count │\n",
       "│ ---                        ┆ ---   │\n",
       "│ str                        ┆ u32   │\n",
       "╞════════════════════════════╪═══════╡\n",
       "│ Gastroenterology           ┆ 224   │\n",
       "│ Cardiovascular / Pulmonary ┆ 371   │\n",
       "│ Surgery                    ┆ 1088  │\n",
       "│ Neurology                  ┆ 223   │\n",
       "│ Radiology                  ┆ 273   │\n",
       "└────────────────────────────┴───────┘"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now count the number of entries we have for each medical speciality.\n",
    "medrec['medical_specialty'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the text in the `report` column has text with both upper and lower case letters. We will convert all the text to lower case to make it easier to work with. We will not moidfy the `report` column, but create a new column `report_lower` that contains the lower case text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>medical_specialty</th><th>report</th><th>report_lower</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Cardiovascular / Pulmonary&quot;</td><td>&quot;2-D M-MODE: , ,1.  Left atrial…</td><td>&quot;2-d m-mode: , ,1.  left atrial…</td></tr><tr><td>&quot;Cardiovascular / Pulmonary&quot;</td><td>&quot;1.  The left ventricular cavit…</td><td>&quot;1.  the left ventricular cavit…</td></tr><tr><td>&quot;Cardiovascular / Pulmonary&quot;</td><td>&quot;2-D ECHOCARDIOGRAM,Multiple vi…</td><td>&quot;2-d echocardiogram,multiple vi…</td></tr><tr><td>&quot;Cardiovascular / Pulmonary&quot;</td><td>&quot;DESCRIPTION:,1.  Normal cardia…</td><td>&quot;description:,1.  normal cardia…</td></tr><tr><td>&quot;Cardiovascular / Pulmonary&quot;</td><td>&quot;2-D STUDY,1. Mild aortic steno…</td><td>&quot;2-d study,1. mild aortic steno…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌────────────────────────────┬─────────────────────────────────┬─────────────────────────────────┐\n",
       "│ medical_specialty          ┆ report                          ┆ report_lower                    │\n",
       "│ ---                        ┆ ---                             ┆ ---                             │\n",
       "│ str                        ┆ str                             ┆ str                             │\n",
       "╞════════════════════════════╪═════════════════════════════════╪═════════════════════════════════╡\n",
       "│ Cardiovascular / Pulmonary ┆ 2-D M-MODE: , ,1.  Left atrial… ┆ 2-d m-mode: , ,1.  left atrial… │\n",
       "│ Cardiovascular / Pulmonary ┆ 1.  The left ventricular cavit… ┆ 1.  the left ventricular cavit… │\n",
       "│ Cardiovascular / Pulmonary ┆ 2-D ECHOCARDIOGRAM,Multiple vi… ┆ 2-d echocardiogram,multiple vi… │\n",
       "│ Cardiovascular / Pulmonary ┆ DESCRIPTION:,1.  Normal cardia… ┆ description:,1.  normal cardia… │\n",
       "│ Cardiovascular / Pulmonary ┆ 2-D STUDY,1. Mild aortic steno… ┆ 2-d study,1. mild aortic steno… │\n",
       "└────────────────────────────┴─────────────────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert a str column in polar to lower case, and it as a new column.\n",
    "medrec = medrec.with_columns(\n",
    "    report_lower=pl.col(\"report\").str.to_lowercase()\n",
    ")\n",
    "medrec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the lower case text in the `report_lower` column to convert the text into n-vectors for clustering the reports. But **what tokens di we use for this purpose?** \n",
    "\n",
    "The file `tokens.txt` in the `data/case_study_01/` folder contains a list of tokens that we will use for this case study. We will not worry about how these tokens were chosen, but we will use them to convert the text data into n-vectors. This is a text file with each token separated by a comma.\n",
    "\n",
    "Let's now read this file and look at the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['impress', 'palpitation', 'gallop', 'compare', 'nonsignificant', 'collect', 'meckel', 'heartburn', 'fundoplication', 'contributory', 'rating', 'psychological', 'huntington', 'epilepsy', 'tended', 'relate', 'sprain', 'cuboid', 'predict', 'version', 'reoperative', 'proximate', 'plication', 'ladder', 'essure']\n",
      "Number of tokens:  25\n"
     ]
    }
   ],
   "source": [
    "with open(tokensfile, \"r\") as f:\n",
    "    tokens = f.read().split(',')\n",
    "print(tokens)\n",
    "# The number of tokens.\n",
    "print(f\"Number of tokens: {len(tokens):3d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use these tokens to convert a given text into a n-vectors (25-vector) to be exact. To do this, we will write our own function that takes in a text and the tokens, and returns the n-vector representation of the text. Run the following code so that we can use it in the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(note: str, tokens: list) -> np.array:\n",
    "    \"\"\"Find the token count in the medical records.\"\"\"\n",
    "    return np.array([note.count(tok) for tok in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this function on some of the reports in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: 1637 [0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 6 0]\n",
      "Row:  957 [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "Row:   22 [0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 1 0 1 0 1]\n",
      "Row: 1229 [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "Row: 1188 [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 1 0 0 0]\n",
      "Row:  547 [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "Row: 2121 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 4]\n",
      "Row: 1898 [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Row: 1971 [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Row: 1793 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "# Get 10 random row numbers for medrec\n",
    "rows = map(int, np.random.randint(0, len(medrec), 10))\n",
    "for _row in rows:\n",
    "    _nvec = count_tokens(medrec[_row, \"report_lower\"], tokens)\n",
    "    print(f\"Row: {_row:4d}\", _nvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Clustering medical rpoets through `kmeans`\n",
    "\n",
    "We now assume that we only have access to the medical reports and not to the speciality they correspond to. We make use of the unique tokens to count the frequency of each of these tokens in each report to generate a set of column vectors for each report. This column vector is then used to compare the similarity between reports, and cluster them.\n",
    "\n",
    "There are many entries from the surgery medical speciality, and thus this will be removed from the data for the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: pathlib not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: pathlib not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Documents/work/teaching/course_material/ALADA-Course/case_studies/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "datadir = pathlib.Path(\"data\")\n",
    "outdir = pathlib.Path(\"output\")\n",
    "outdir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: pathlib not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: pathlib not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Documents/work/teaching/course_material/ALADA-Course/case_studies/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X20sZmlsZQ==.jl:2"
     ]
    }
   ],
   "source": [
    "# Read header for tokens\n",
    "datafile = (datadir / pathlib.Path(\"reports.csv\")).as_posix()\n",
    "with open(datafile, \"r\") as f:\n",
    "    tokens = [_s.strip() for _s in f.readline().split(':')[-1].split(\",\")]\n",
    "\n",
    "# Read the medical records file.\n",
    "medrec = pd.read_csv(datafile, skiprows=2)\n",
    "medrec[\"medical_specialty\"].value_counts()\n",
    "# Make the reports column lower case\n",
    "medrec[\"report_lower\"] = medrec[\"report\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: medrec not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: medrec not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Documents/work/teaching/course_material/ALADA-Course/case_studies/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X21sZmlsZQ==.jl:2"
     ]
    }
   ],
   "source": [
    "# Get the token vectors for each medical note.\n",
    "inx = medrec[\"medical_specialty\"] != \"Surgery\"\n",
    "medrec = medrec[inx]\n",
    "medrec.reset_index(inplace=True, drop=True)\n",
    "tokvec = np.array([count_tokens(_v, tokens) for _v in medrec['report_lower'].values])\n",
    "tokvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "km = chap01.KMeans(X=tokvec, k=4)\n",
    "cm, ca, j = km.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the medical specialty for each cluster\n",
    "medrec[\"cluster\"] = ca[-1]\n",
    "# Print value counts for different clusters.\n",
    "for _c in range(k):\n",
    "    print(f\"Cluster {_c}: {np.linalg.norm(cm[-1][_c]): .3f}\")\n",
    "    print(medrec[medrec[\"cluster\"] == _c][\"medical_specialty\"].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cm[-1].T + np.array([0, 1, 2, 3]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using k-means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_assignment(tvec, mvec):\n",
    "    return np.argmin(np.linalg.norm(mvec - tvec, axis=1))\n",
    "\n",
    "def get_cluster_mean(tokvec, clustassign):\n",
    "    return np.array([np.mean(tokvec[clustassign == _c, :], axis=0)\n",
    "                     for _c in np.unique(clustassign)])\n",
    "\n",
    "def get_j_clust(tokvec, mvec, clustassign):\n",
    "    return np.sum([np.sum(np.square(np.linalg.norm(tokvec[clustassign == _c, :] - mvec[_i, :], axis=1))) for _i, _c in enumerate(np.unique(clustassign))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "# Random starting means.\n",
    "mvec = tokvec[list(np.random.randint(0, tokvec.shape[0], k)), :]\n",
    "\n",
    "# Cluster assingment for the random means.\n",
    "clustassign = np.array([get_cluster_assignment(_tvec, mvec) for _tvec in tokvec])\n",
    "\n",
    "# Compute J_clust\n",
    "J_clust_curr = get_j_clust(tokvec, mvec, clustassign)\n",
    "\n",
    "# Iterate now.\n",
    "n_iter = 20\n",
    "for i in range(n_iter):\n",
    "    # Update the means.\n",
    "    mvec = get_cluster_mean(tokvec, clustassign)\n",
    "    \n",
    "    # Update the cluster assignment.\n",
    "    clustassign = np.array([get_cluster_assignment(_tvec, mvec) for _tvec in tokvec])\n",
    "    \n",
    "    # Update J_clust\n",
    "    J_clust_prev = J_clust_curr\n",
    "    J_clust_curr = get_j_clust(tokvec, mvec, clustassign)\n",
    "\n",
    "    print(f\"Iteration: {i:2d}, J_clust: {J_clust_curr:6.2f}, Change: {100 * (J_clust_curr - J_clust_prev) / J_clust_prev:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for performing k-means algorithm \n",
    "def get_cluster_assignment(tvec, mvec):\n",
    "    return np.argmin(np.linalg.norm(mvec - tvec, axis=1))\n",
    "\n",
    "def get_cluster_mean(tokvec, clustassign):\n",
    "    return np.array([np.mean(tokvec[clustassign == _c, :], axis=0)\n",
    "                     for _c in np.unique(clustassign)])\n",
    "\n",
    "def get_j_clust(tokvec, mvec, clustassign):\n",
    "    return np.sum([np.sum(np.square(np.linalg.norm(tokvec[clustassign == _c, :] - mvec[_i, :], axis=1))) for _i, _c in enumerate(np.unique(clustassign))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of kmean class from chap01 module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "_x1 = np.random.randn(100, 2) + np.array([4, 4])\n",
    "_x2 = np.random.randn(100, 2)\n",
    "X = np.vstack([_x1, _x2])\n",
    "# Randomly reorder the rows\n",
    "np.random.shuffle(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=2\n",
    "km = chap01.KMeans(X, 2)\n",
    "cm, ca, j = km.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the k-mean algorithm evolution.\n",
    "colors = [\"tab:blue\", \"tab:red\", \"tab:green\", \"tab:orange\", \"tab:purple\", \"tab:brown\", \"tab:pink\", \"tab:gray\", \"tab:olive\", \"tab:cyan\"]\n",
    "n = len(cm)\n",
    "m = (n // 5) + 1\n",
    "fig = plt.figure(figsize=(15, 2.5 * m))\n",
    "for i in range(n):\n",
    "    ax = fig.add_subplot(m, 5, i + 1)\n",
    "    for _k in range(k):\n",
    "        ax.scatter(X[ca[i] == _k, 0], X[ca[i] == _k, 1], s=25, color=colors[_k],\n",
    "                   marker=\"x\", alpha=0.2)\n",
    "    for _k in range(k):\n",
    "        ax.scatter(cm[i][_k, 0], cm[i][_k, 1], s=50, marker=\"o\", alpha=1, \n",
    "                   color=colors[_k], edgecolors=\"black\") \n",
    "    ax.set_title(f\"Iter: {i + 1}: J = {j[i]:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [167, 102, 36.6],\n",
    "    [180, 87, 26.9],\n",
    "    [177, 78, 24.9],\n",
    "    [152, 76, 32.9],\n",
    "]).T\n",
    "\n",
    "# Compute the distance between the points.\n",
    "np.array([[np.linalg.norm(_v1 - _v2) for _v2 in X.T] for _v1 in X.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X * np.array([0.01, 1, 1]).reshape(-1, 1)\n",
    "# Compute the distance between the points.\n",
    "np.array([[np.linalg.norm(_v1 - _v2) for _v2 in X1.T] for _v1 in X1.T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Angle similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_between(v1, v2):\n",
    "    return (180 / np.pi) * np.arccos(np.max([-1, np.min([1, np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))])]))\n",
    "\n",
    "# Compute the distance between the points.\n",
    "np.round(100 * np.array([[angle_between(_v1, _v2) for _v2 in X.T] for _v1 in X.T])) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the distance between the points.\n",
    "np.round(100 * np.array([[angle_between(_v1, _v2) for _v2 in X1.T] for _v1 in X1.T])) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(100 * np.array([v / np.linalg.norm(v) for v in X.T]).T) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(100 * np.array([v / np.linalg.norm(v) for v in X1.T]).T) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
